{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ChromaDB Data Pipes \ud83d\udd87\ufe0f - The easiest way to get data into and out of ChromaDB","text":"<p>ChromaDB Data Pipes is a collection of tools to build data pipelines for Chroma DB, inspired by the Unix philosophy of \" do one thing and do it well\".</p> <p>Roadmap:</p> <ul> <li>Integration with LangChain \ud83e\udd9c\ud83d\udd17</li> <li>Integration with LlamaIndex \ud83e\udd99</li> <li>Support more than <code>all-MiniLM-L6-v2</code> as embedding functions</li> <li>Multimodal support</li> <li>Much more!</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install chromadb-data-pipes\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<p>Get help:</p> <pre><code>cdp --help\n</code></pre>"},{"location":"#importing","title":"Importing","text":"<p>Import data from HuggingFace Datasets to <code>.jsonl</code> file:</p> <pre><code>cdp imp hf --uri \"hf:tazarov/chroma-qna?split=train\" &gt; chroma-qna.jsonl\n</code></pre> <p>Import data from HuggingFace Datasets to Chroma DB:</p> <p>The below command will import the <code>train</code> split of the given dataset to Chroma chroma-qna <code>chroma-qna</code> collection. The collection will be created if it does not exist and documents will be upserted.</p> <pre><code>cdp imp hf --uri \"hf://tazarov/chroma-qna?split=train\" | cdp imp chroma --uri \"http://localhost:8000/default_database/chroma-qna\" --upsert --create\n</code></pre> <p>Importing from a directory with PDF files:</p> <pre><code>cdp imp pdf sample-data/papers/ |grep \"2401.02412.pdf\" | head -1 | cdp tx chunk -s 500 | cdp tx embed --ef default | cdp imp chroma --uri \"http://localhost:8000/default_database/my-pdfs\" --upsert --create\n</code></pre> <p>Note</p> <p>The above command will import the first PDF file from the <code>sample-data/papers/</code> directory, chunk it into 500 word chunks, embed each chunk and import the chunks to the <code>my-pdfs</code> collection in Chroma DB.</p>"},{"location":"#exporting","title":"Exporting","text":"<p>Export data from Chroma DB to <code>.jsonl</code> file:</p> <p>The below command will export the first 10 documents from the <code>chroma-qna</code> collection to <code>chroma-qna.jsonl</code> file.</p> <pre><code>cdp exp chroma --uri \"http://localhost:8000/default_database/chroma-qna\" --limit 10 &gt; chroma-qna.jsonl\n</code></pre> <p>Export data from Chroma DB to HuggingFace Datasets:</p> <p>The below command will export the first 10 documents with offset 10 from the <code>chroma-qna</code> collection to HuggingFace Datasets <code>tazarov/chroma-qna</code> dataset. The dataset will be uploaded to HF.</p> <p>Note</p> <p>Make sure you have <code>HF_TOKEN=hf_....</code> environment variable set. If you want your dataset to be private, add <code>--private</code> flag to the <code>cdp exp hf</code> command.</p> <pre><code>cdp exp chroma --uri \"http://localhost:8000/default_database/chroma-qna\" --limit 10 --offset 10 | cdp exp hf --uri \"hf://tazarov/chroma-qna-modified\"\n</code></pre> <p>To export a dataset to a file, use <code>--uri</code> with <code>file://</code> prefix:</p> <pre><code>cdp exp chroma --uri \"http://localhost:8000/default_database/chroma-qna\" --limit 10 --offset 10 | cdp exp hf --uri \"file://chroma-qna\"\n</code></pre> <p>Note</p> <p>The file is  relative to the current working directory.</p>"},{"location":"#processing","title":"Processing","text":"<p>Copy collection from one Chroma collection to another and re-embed the documents:</p> <pre><code>cdp exp chroma --uri \"http://localhost:8000/default_database/chroma-qna\" | cdp tx embed --ef default | cdp imp chroma --uri \"http://localhost:8000/default_database/chroma-qna-def-emb\" --upsert --create\n</code></pre> <p>Import dataset from HF to Chroma and embed the documents:</p> <pre><code>cdp imp hf --uri \"hf://tazarov/ds2?split=train\" | cdp tx embed --ef default | cdp imp chroma --uri \"http://localhost:8000/default_database/chroma-qna-def-emb-hf\" --upsert --create\n</code></pre> <p>Chunk Large Documents:</p> <pre><code>cdp imp pdf sample-data/papers/ | grep \"2401.02412.pdf\" | head -1 | cdp tx chunk -s 500\n</code></pre>"},{"location":"#misc","title":"Misc","text":"<p>Count the number of documents in a collection:</p> <pre><code>cdp exp chroma --uri \"http://localhost:8000/default_database/chroma-qna\" | wc -l\n</code></pre>"},{"location":"concepts/","title":"CDP Concepts","text":""},{"location":"concepts/#producer","title":"Producer","text":"<p>Generates a stream of data to a file or stdout.</p> <p>The source of the data is implementation dependent, HF datasets, ChromaDB, file etc.</p>"},{"location":"concepts/#consumer","title":"Consumer","text":"<p>Consumes a stream of data from a file or stdin.</p>"},{"location":"concepts/#processor","title":"Processor","text":"<p>Consumes a stream of data from a file or stdin and processes it by some criteria. Produces a stream of data to a file or stdout.</p>"},{"location":"concepts/#pipeline","title":"Pipeline","text":"<p>Reusable set of producer, consumer, filter, and transformer.</p> <p>Properties: - Variables</p>"},{"location":"processors/chunking/","title":"Chunking","text":"<p>To chunk documents we have a chunk processor - <code>cdp tx chunk</code> that can be used as follows:</p> <pre><code>cdp imp pdf sample-data/papers/ | grep \"2401.02412.pdf\" | head -1 | cdp tx chunk -s 500 -a\n</code></pre> <p>The above will chunk the document into 500 character chunks and print the chunks to stdout. We will also add (<code>-a</code> option) the offset position of each chunk within the document as metadata <code>start_index</code>.</p> <p>Alternatively you can chunk from an input <code>jsonl</code> file:</p> <p>Create a <code>jsonl</code> file</p> <pre><code>cdp imp pdf sample-data/papers/ | grep \"2401.02412.pdf\" | head -1 | &gt; chunk.jsonl\n</code></pre> <p>jsonl format</p> <p>It is expected that the <code>jsonl</code> file contains <code>chroma_dp.EmbeddableTextResource</code> objects (one per line).</p> <pre><code>cdp tx chunk -s 500 --in chunk.jsonl\n</code></pre> <p>Help</p> <p>Run <code>cdp tx chunk --help</code> for more information.</p>"},{"location":"producers/pdf/","title":"PDFs","text":""},{"location":"producers/pdf/#pypdf","title":"PyPDF","text":"<p>Reading a dir with PDF files to stdout:</p> <pre><code>cdp imp pdf sample-data/papers/\n</code></pre> <p>Help</p> <p>Run <code>cdp imp pdf --help</code> for more information.</p>"}]}